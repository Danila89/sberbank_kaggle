{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#     The data used in this notebook was cleaned by the script by MadScientist:\n",
    "#     https://www.kaggle.com/keremt/very-extensive-cleaning-by-sberbank-discussions\n",
    "#\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "def preprocess(data):\n",
    "    #add relative floor\n",
    "    data['rel_floor'] = data['floor']/data['max_floor']\n",
    "    #add relative kitch_sq\n",
    "    data['relative_kitch_sq'] = data['kitch_sq']/data['full_sq']\n",
    "    #add room size\n",
    "    data['room_size'] = data['life_sq']/data['num_room']\n",
    "    # add month and day of week\n",
    "    data['month'] = data.timestamp.dt.month.astype(int)\n",
    "    data['day_of_week'] = data.timestamp.dt.dayofweek.astype(int)\n",
    "    \n",
    "    data['bought_minus_built'] = data.timestamp.dt.year.astype(int) - data['build_year']\n",
    "    \n",
    "    data.loc[data['full_sq']==data['life_sq'],'life_sq'] = np.nan\n",
    "    return data\n",
    "def fact_binary(data):\n",
    "    data = data.applymap(lambda x: x if x!='yes' else 1)\n",
    "    data = data.applymap(lambda x: x if x!='no' else 0)\n",
    "    data = data.applymap(lambda x: x if x!='OwnerOccupier' else 0)\n",
    "    data = data.applymap(lambda x: x if x!='Investment' else 1)\n",
    "    return data\n",
    "class sep_estimator:\n",
    "    def __init__(self,owner_params,investment_params):\n",
    "        self.est1 = xgb.XGBRegressor(**owner_params)\n",
    "        self.est2 = xgb.XGBRegressor(**investment_params)\n",
    "    def preprocess_owner(self,data,mode):\n",
    "        assert (data['product_type'].values==0).all()\n",
    "        if mode=='predict':\n",
    "            data.loc[data['full_sq'].isnull(),'full_sq'] = 50\n",
    "        data = data.drop('timestamp',axis=1)\n",
    "        return data\n",
    "    def preprocess_investment(self,data,mode):\n",
    "        if mode=='predict':\n",
    "            assert (data['product_type'].values==1).all()\n",
    "            data.loc[data['full_sq'].isnull(),'full_sq'] = 50\n",
    "        data = data.drop('timestamp',axis=1)\n",
    "        return data\n",
    "    def fit(self,X,y):\n",
    "        X1 = X[X['product_type']==0]\n",
    "        X2 = X\n",
    "        X1 = self.preprocess_owner(X1,'train')\n",
    "        y1 = y.loc[X1.index.values]/X1['full_sq']\n",
    "        X2 = self.preprocess_investment(X2,'train')\n",
    "        y2 = y\n",
    "        y2 = y2/X2['full_sq']\n",
    "        if len(X1)>0:\n",
    "            self.est1.fit(X1,y1)\n",
    "        if len(X2)>0:\n",
    "            self.est2.fit(X2,y2)\n",
    "    def predict(self,X):\n",
    "        X1 = X[X['product_type']==0]\n",
    "        X2 = X[X['product_type']==1]\n",
    "        owner_index = X1.index.values\n",
    "        investment_index = X.index.drop(owner_index).values\n",
    "        X1 = self.preprocess_owner(X1,'predict')\n",
    "        X2 = self.preprocess_investment(X2,'predict')\n",
    "        res = pd.DataFrame(index=X.index)\n",
    "        if len(X1)>0:\n",
    "            pred1 = self.est1.predict(X1)\n",
    "            res.loc[owner_index,0] = pred1*X1['full_sq']\n",
    "        if len(X2)>0:\n",
    "            pred2 = self.est2.predict(X2)\n",
    "            res.loc[investment_index,0] = pred2*X2['full_sq']     \n",
    "        return res[0].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_corr_clean.csv',index_col='id',parse_dates=['timestamp'])\n",
    "data = fact_binary(data)\n",
    "data = preprocess(data)\n",
    "data = data.drop(['sub_area','ecology'],axis=1)\n",
    "data = data.loc[~data['full_sq'].isnull(),:]\n",
    "train = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    Price level multipliers here. I've copied it from Andy Harless script:\n",
    "#    https://www.kaggle.com/aharless/exercising-the-exorcism\n",
    "#\n",
    "#\n",
    "\n",
    "rate_2015_q2 = 1\n",
    "rate_2015_q1 = rate_2015_q2 / 0.9932\n",
    "rate_2014_q4 = rate_2015_q1 / 1.0112\n",
    "rate_2014_q3 = rate_2014_q4 / 1.0169\n",
    "rate_2014_q2 = rate_2014_q3 / 1.0086\n",
    "rate_2014_q1 = rate_2014_q2 / 1.0126\n",
    "rate_2013_q4 = rate_2014_q1 / 0.9902\n",
    "rate_2013_q3 = rate_2013_q4 / 1.0041\n",
    "rate_2013_q2 = rate_2013_q3 / 1.0044\n",
    "rate_2013_q1 = rate_2013_q2 / 1.0104  # This is 1.002 (relative to mult), close to 1:\n",
    "rate_2012_q4 = rate_2013_q1 / 0.9832  #     maybe use 2013q1 as a base quarter and get rid of mult?\n",
    "rate_2012_q3 = rate_2012_q4 / 1.0277\n",
    "rate_2012_q2 = rate_2012_q3 / 1.0279\n",
    "rate_2012_q1 = rate_2012_q2 / 1.0279\n",
    "rate_2011_q4 = rate_2012_q1 / 1.076\n",
    "rate_2011_q3 = rate_2011_q4 / 1.0236\n",
    "rate_2011_q2 = rate_2011_q3 / 1\n",
    "rate_2011_q1 = rate_2011_q2 / 1.011\n",
    "\n",
    "\n",
    "# train 2015\n",
    "train['average_q_price'] = 1\n",
    "\n",
    "train_2015_q2_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2015_q2_index, 'average_q_price'] = rate_2015_q2\n",
    "\n",
    "train_2015_q1_index = train.loc[train['timestamp'].dt.year == 2015].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2015_q1_index, 'average_q_price'] = rate_2015_q1\n",
    "\n",
    "\n",
    "# train 2014\n",
    "train_2014_q4_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2014_q4_index, 'average_q_price'] = rate_2014_q4\n",
    "\n",
    "train_2014_q3_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2014_q3_index, 'average_q_price'] = rate_2014_q3\n",
    "\n",
    "train_2014_q2_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2014_q2_index, 'average_q_price'] = rate_2014_q2\n",
    "\n",
    "train_2014_q1_index = train.loc[train['timestamp'].dt.year == 2014].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2014_q1_index, 'average_q_price'] = rate_2014_q1\n",
    "\n",
    "\n",
    "# train 2013\n",
    "train_2013_q4_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2013_q4_index, 'average_q_price'] = rate_2013_q4\n",
    "\n",
    "train_2013_q3_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2013_q3_index, 'average_q_price'] = rate_2013_q3\n",
    "\n",
    "train_2013_q2_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2013_q2_index, 'average_q_price'] = rate_2013_q2\n",
    "\n",
    "train_2013_q1_index = train.loc[train['timestamp'].dt.year == 2013].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2013_q1_index, 'average_q_price'] = rate_2013_q1\n",
    "\n",
    "\n",
    "# train 2012\n",
    "train_2012_q4_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2012_q4_index, 'average_q_price'] = rate_2012_q4\n",
    "\n",
    "train_2012_q3_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2012_q3_index, 'average_q_price'] = rate_2012_q3\n",
    "\n",
    "train_2012_q2_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2012_q2_index, 'average_q_price'] = rate_2012_q2\n",
    "\n",
    "train_2012_q1_index = train.loc[train['timestamp'].dt.year == 2012].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2012_q1_index, 'average_q_price'] = rate_2012_q1\n",
    "\n",
    "\n",
    "# train 2011\n",
    "train_2011_q4_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 10].loc[train['timestamp'].dt.month <= 12].index\n",
    "train.loc[train_2011_q4_index, 'average_q_price'] = rate_2011_q4\n",
    "\n",
    "train_2011_q3_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 7].loc[train['timestamp'].dt.month < 10].index\n",
    "train.loc[train_2011_q3_index, 'average_q_price'] = rate_2011_q3\n",
    "\n",
    "train_2011_q2_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 4].loc[train['timestamp'].dt.month < 7].index\n",
    "train.loc[train_2011_q2_index, 'average_q_price'] = rate_2011_q2\n",
    "\n",
    "train_2011_q1_index = train.loc[train['timestamp'].dt.year == 2011].loc[train['timestamp'].dt.month >= 1].loc[train['timestamp'].dt.month < 4].index\n",
    "train.loc[train_2011_q1_index, 'average_q_price'] = rate_2011_q1\n",
    "\n",
    "train['price_doc'] = train['price_doc'] * train['average_q_price']\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "X = train.drop([\"price_doc\", \"average_q_price\"],axis=1)\n",
    "y = train['price_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kaggle_test = pd.read_csv('test_corr_clean.csv', parse_dates=['timestamp'],index_col='id')\n",
    "test1 = kaggle_test.copy()\n",
    "test1 = preprocess(test1)\n",
    "test1 = fact_binary(test1)\n",
    "#test1 = test1.merge(macro,on='timestamp')\n",
    "test1 = test1.drop(['ecology','sub_area'],axis=1)\n",
    "test1.loc[test1['full_sq'].isnull(),'full_sq'] = 50\n",
    "test1.loc[test1['product_type'].isnull(),'product_type'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "for i in range(400):\n",
    "    owner_params = {\n",
    "            'n_estimators':100,\n",
    "            'learning_rate':0.1,\n",
    "            'max_depth':7,\n",
    "            'min_child_weight':1,\n",
    "            'subsample':0.8,\n",
    "            'colsample_bytree':0.9,\n",
    "            'colsample_bylevel':1,\n",
    "            'reg_alpha':0,\n",
    "            'reg_lambda':1,\n",
    "            'seed':i,\n",
    "            'objective':'reg:linear',\n",
    "            'nthread':8\n",
    "    }\n",
    "    investment_params = {\n",
    "            'n_estimators':100,\n",
    "            'learning_rate':0.1,\n",
    "            'max_depth':7,\n",
    "            'min_child_weight':1,\n",
    "            'subsample':0.8,\n",
    "            'colsample_bytree':0.9,\n",
    "            'colsample_bylevel':1,\n",
    "            'reg_alpha':0,\n",
    "            'reg_lambda':1,\n",
    "            'seed':i,\n",
    "            'objective':'reg:linear',\n",
    "            'nthread':8\n",
    "    }\n",
    "    est = sep_estimator(owner_params=owner_params,investment_params=investment_params)\n",
    "    est.fit(X,y)\n",
    "    estimators.append(est)\n",
    "    if i%10==0:\n",
    "        print i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:476: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5.503016e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>8.358840e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5.344753e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>6.311780e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5.117794e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     price_doc\n",
       "0  30474  5.503016e+06\n",
       "1  30475  8.358840e+06\n",
       "2  30476  5.344753e+06\n",
       "3  30477  6.311780e+06\n",
       "4  30478  5.117794e+06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = np.zeros(shape=test1.values.shape[0])\n",
    "cnt = 0\n",
    "for e1 in estimators:\n",
    "    pr = e1.predict(test1)\n",
    "    pred_test += pr\n",
    "    if cnt%10 == 0:\n",
    "        print cnt\n",
    "    cnt += 1\n",
    "pred_test /= len(estimators)\n",
    "pred_test *= 0.9915\n",
    "subm = pd.read_csv('sample_submission.csv')\n",
    "subm['price_doc'] = pred_test\n",
    "subm.to_csv('model_1_output.csv',index=False)\n",
    "subm.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
